const OpenAI = require('openai');
const fs = require('fs');
const { logInfo, logError } = require('../utils/logger');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

/**
 * Transcribe audio file to text using OpenAI Whisper
 * @param {string} audioPath - Path to audio file
 * @returns {Promise<string>} - Transcribed text
 */
async function transcribeAudio(audioPath) {
  try {
    logInfo(`üéôÔ∏è Transcribiendo audio: ${audioPath}`);
    
    if (!fs.existsSync(audioPath)) {
      throw new Error(`Archivo de audio no encontrado: ${audioPath}`);
    }

    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(audioPath),
      model: 'whisper-1',
      language: 'es', // Espa√±ol
      response_format: 'text',
      temperature: 0.2 // Menor temperatura para mayor precisi√≥n
    });

    const text = transcription.trim();
    logInfo(`üìù Texto transcrito: "${text}"`);
    
    return text;
    
  } catch (error) {
    logError('Error en transcripci√≥n:', error);
    
    if (error.message.includes('audio_longer_than_max_duration')) {
      throw new Error('El audio es demasiado largo. M√°ximo 25MB o 25 minutos.');
    }
    
    if (error.message.includes('invalid_file_format')) {
      throw new Error('Formato de audio no v√°lido. Usa WAV, MP3, M4A, etc.');
    }
    
    throw new Error(`Error de transcripci√≥n: ${error.message}`);
  }
}

/**
 * Transcribe audio from buffer (√∫til para streams)
 * @param {Buffer} audioBuffer - Audio buffer
 * @param {string} filename - Filename with extension
 * @returns {Promise<string>} - Transcribed text
 */
async function transcribeAudioBuffer(audioBuffer, filename = 'audio.wav') {
  try {
    logInfo('üéôÔ∏è Transcribiendo audio desde buffer');
    
    // Crear archivo temporal
    const tempPath = `uploads/temp-${Date.now()}-${filename}`;
    fs.writeFileSync(tempPath, audioBuffer);
    
    // Transcribir
    const text = await transcribeAudio(tempPath);
    
    // Limpiar archivo temporal
    fs.unlinkSync(tempPath);
    
    return text;
    
  } catch (error) {
    logError('Error transcribiendo buffer:', error);
    throw error;
  }
}

/**
 * Valida que el audio sea v√°lido para transcripci√≥n
 * @param {string} audioPath - Path to audio file
 * @returns {boolean} - True if valid
 */
function validateAudioFile(audioPath) {
  try {
    if (!fs.existsSync(audioPath)) {
      return false;
    }
    
    const stats = fs.statSync(audioPath);
    const fileSizeInMB = stats.size / (1024 * 1024);
    
    // Whisper tiene l√≠mite de 25MB
    if (fileSizeInMB > 25) {
      logError(`Archivo muy grande: ${fileSizeInMB}MB (m√°ximo 25MB)`);
      return false;
    }
    
    return true;
    
  } catch (error) {
    logError('Error validando archivo de audio:', error);
    return false;
  }
}

/**
 * Obtiene informaci√≥n del archivo de audio
 * @param {string} audioPath - Path to audio file
 * @returns {object} - Audio file info
 */
function getAudioInfo(audioPath) {
  try {
    if (!fs.existsSync(audioPath)) {
      return null;
    }
    
    const stats = fs.statSync(audioPath);
    const fileSizeInMB = stats.size / (1024 * 1024);
    
    return {
      path: audioPath,
      sizeInMB: fileSizeInMB.toFixed(2),
      sizeInBytes: stats.size,
      createdAt: stats.birthtime,
      modifiedAt: stats.mtime
    };
    
  } catch (error) {
    logError('Error obteniendo info del audio:', error);
    return null;
  }
}

module.exports = {
  transcribeAudio,
  transcribeAudioBuffer,
  validateAudioFile,
  getAudioInfo
};